import asyncio
import edge_tts
import os
import json 
from pptx import Presentation
from openai import OpenAI
import tempfile
import shutil
import time
from tqdm import tqdm
from PIL import Image
import numpy as np
import win32com.client as win32
from moviepy.video.VideoClip import ImageClip
from moviepy.video.io.ImageSequenceClip import ImageSequenceClip
from moviepy import concatenate_videoclips
from moviepy import AudioFileClip

async def generate_tts_async(text, path, voice="zh-CN-XiaoxiaoNeural", rate="+0%"):
    communicate = edge_tts.Communicate(text=text, voice=voice, rate=rate)
    await communicate.save(path)

def generate_voice_for_slides(ppt_content, output_dir="voice_audio"):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    loop = asyncio.get_event_loop()
    
    # ç”Ÿæˆå°é¢çš„è¯­éŸ³æ–‡ä»¶
    cover_text = ppt_content['title'] + "\n" + "æ±‰èµ‹è‡ªä¹ å®¤"  # å‡è®¾å°é¢å‰¯æ ‡é¢˜æ˜¯ "æ±‰èµ‹è‡ªä¹ å®¤"
    cover_filename = os.path.join(output_dir, f"slide_000.mp3")
    print(f"æ­£åœ¨ä¸ºå°é¢åˆæˆè¯­éŸ³...")
    loop.run_until_complete(generate_tts_async(cover_text, cover_filename))
    loop = asyncio.get_event_loop()
    for idx, page in enumerate(ppt_content['pages']):
        # æ­£ç¡®ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥ï¼ˆç§»é™¤å¤šä½™çš„åæ–œæ è½¬ä¹‰ï¼‰
        text = page['title'] + "\n" + "\n".join(
            f"{blk['title']}ã€‚{blk['description']}" for blk in page['content']
        )
        filename = os.path.join(output_dir, f"slide_{idx+1:03d}.mp3")
        print(f"æ­£åœ¨ä¸ºç¬¬ {idx+2} é¡µåˆæˆè¯­éŸ³...")
        loop.run_until_complete(generate_tts_async(text, filename))
    return output_dir
    
def estimate_ppt_pages_from_content(text, target_chars_per_page=200, min_pages=5, max_pages=15):
    char_count = len(text.replace('\\n', '').replace(' ', ''))
    estimated = max(min_pages, min(max_pages, char_count // target_chars_per_page + 1))
    return estimated

def return_llm(query, history=[], user_stop_words=[]): 
    client = OpenAI(api_key="sk-jrvcstpnxgsoxwsaehhwmasgggywdvgeeaurlltclfckgfcn", 
    base_url="https://api.siliconflow.cn/v1")

    messages = [{'role': 'system', 'content': 'You are a helpful assistant.'}]
    for hist in history:
        messages.append({'role': 'user', 'content': hist[0]})
        messages.append({'role': 'assistant', 'content': hist[1]})
    messages.append({'role': 'user', 'content': query})

    response = client.chat.completions.create(
        model="Qwen/Qwen2.5-72B-Instruct",
        messages=messages,
        stream=True
    )

    full_response = ""
    for chunk in response:
        if chunk.choices[0].delta.content:
            full_response += chunk.choices[0].delta.content
    return full_response

def generate_ppt_content(topic, pages):
    output_format = json.dumps({
        "title": "example title",
        "pages": [
            {
                "title": "title for page 1",
                "content": [
                    {
                        "title": "title for paragraph 1",
                        "description": "detail for paragraph 1",
                    }
                ],
            }
        ],
    }, ensure_ascii=True)
    
    prompt = f'''æˆ‘è¦å‡†å¤‡1ä¸ªå…³äº{topic}çš„PPTï¼Œè¦æ±‚ä¸€å…±å†™{pages}é¡µï¼Œè¯·ä½ æ ¹æ®ä¸»é¢˜ç”Ÿæˆè¯¦ç»†å†…å®¹ï¼Œæ¯ä¸€ç‚¹å†™ä¸‰åˆ°äº”å¥è¯å°±è¡Œã€‚
    ä¸¥æ ¼æŒ‰è¿™ä¸ªJSONæ ¼å¼è¾“å‡º{output_format}ï¼Œåªèƒ½è¿”å›JSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å­—ç¬¦ï¼Œè¯·è®¤çœŸæ£€æŸ¥ç”Ÿæˆçš„JSONæ–‡æœ¬çš„åˆæ³•æ€§ï¼Œå¦‚å¼•å·æœªé—­åˆç­‰é—®é¢˜ã€‚ä¸”JSONä¸è¦ç”¨```åŒ…è£¹ï¼Œå†…å®¹è¦ç”¨ä¸­æ–‡ã€‚'''

    prompt_topic = f'''è¯·æ ¹æ®æˆ‘ç»™å‡ºçš„ä¸»é¢˜ï¼š{topic},é‡æ–°ç”Ÿæˆä¸€ä¸ªä¹¦é¢åŒ–çš„ï¼Œ
                       å¯ä»¥ä½œä¸ºè¯¾ä»¶pptæ ‡é¢˜çš„åç§°ï¼Œç›´æ¥ç»™å‡ºè¯¥åç§°ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å­—ç¬¦ä¸æ ‡ç‚¹ç¬¦å·ã€‚
                       ç¤ºä¾‹ï¼š
                       é—®é¢˜ï¼šå‡¯æ©æ–¯ä¸»ä¹‰æ˜¯å•¥å•Š
                       é”™è¯¯å›ç­”ï¼šå‡¯æ©æ–¯ä¸»ä¹‰æ¦‚è¿°ä¸è§£æ
                       æ­£ç¡®å›ç­”ï¼šå‡¯æ©æ–¯ä¸»ä¹‰
                       åªèƒ½è¿”å›JSONï¼Œä¸”JSONä¸è¦ç”¨```åŒ…è£¹ï¼Œå†…å®¹è¦ç”¨ä¸­æ–‡ã€‚'''

    topic_refined_json = json.loads(return_llm(prompt_topic))
    topic_refined = topic_refined_json if isinstance(topic_refined_json, str) else list(topic_refined_json.values())[0]

    ppt_content = json.loads(return_llm(prompt))
    return ppt_content, topic_refined


def generate_ppt_file(topic, ppt_content):
    ppt = Presentation()
    
    slide = ppt.slides.add_slide(ppt.slide_layouts[0]) 
    slide.placeholders[0].text = ppt_content['title']
    slide.placeholders[1].text = "æ±‰èµ‹è‡ªä¹ å®¤"
    
    print('æ€»å…±%dé¡µ...' % len(ppt_content['pages']))
    for i, page in enumerate(ppt_content['pages']):
        print('ç”Ÿæˆç¬¬%dé¡µ:%s' % (i + 1, page['title']))
        slide = ppt.slides.add_slide(ppt.slide_layouts[1]) 
        slide.placeholders[0].text = page['title']
        for sub_content in page['content']:
            sub_title = slide.placeholders[1].text_frame.add_paragraph()
            sub_title.text, sub_title.level = sub_content['title'], 1
            sub_description = slide.placeholders[1].text_frame.add_paragraph()
            sub_description.text, sub_description.level = sub_content['description'], 2
    
    ppt_path = f'{topic}.pptx'
    ppt.save(ppt_path)
    return os.path.abspath(ppt_path)

def emu_to_pixels(emu, dpi=96):
    return int((emu / 914400) * dpi)

def add_background_to_ppt(ppt_path_background, bg_image_path):
    prs = Presentation(ppt_path_background)
    slide_width = prs.slide_width
    slide_height = prs.slide_height

    slide_width_px = emu_to_pixels(slide_width)
    slide_height_px = emu_to_pixels(slide_height)

    bg_img = Image.open(bg_image_path).convert("RGB")
    bg_img = bg_img.resize((slide_width_px, slide_height_px))
    temp_img_path = "resized_bg_temp.jpg"
    bg_img.save(temp_img_path)

    for slide in prs.slides:
        bg_shape = slide.shapes.add_picture(temp_img_path, 0, 0, width=slide_width, height=slide_height)
        slide.shapes._spTree.remove(bg_shape._element)
        slide.shapes._spTree.insert(2, bg_shape._element)

    output_path_background = f'{topic}_background.pptx'
    prs.save(output_path_background)
    os.remove(temp_img_path)
    return os.path.abspath(output_path_background)

def get_slide_durations_from_content(ppt_content, seconds_per_char=0.15, min_duration=1):
    durations = []
    # å°é¢æ—¶é•¿
    cover_text = ppt_content['title'] + "\n" + "æ±‰èµ‹è‡ªä¹ å®¤"
    cover_char_count = len(cover_text.strip())
    cover_duration = max(min_duration, cover_char_count * seconds_per_char)
    durations.append(cover_duration)
    for page in ppt_content['pages']:
        total_text = page['title']
        for block in page['content']:
            total_text += block['title'] + block['description']
        char_count = len(total_text.strip())
        duration = max(min_duration, char_count * seconds_per_char)
        durations.append(duration)
    return durations

def ppt_to_video(ppt_path, output_path, durations=None, fps=30, transition_duration=1):
    if not os.path.exists(ppt_path):
        print(f"é”™è¯¯: æ–‡ä»¶ '{ppt_path}' ä¸å­˜åœ¨ã€‚")
        return
    
    temp_dir = tempfile.mkdtemp()
    image_dir = os.path.join(temp_dir, "images")
    os.makedirs(image_dir, exist_ok=True)
    
    print(f"æ­£åœ¨å¯¼å‡ºPPTå¹»ç¯ç‰‡ä¸ºå›¾åƒ...")
    try:
        powerpoint = win32.gencache.EnsureDispatch('PowerPoint.Application')
        presentation = powerpoint.Presentations.Open(ppt_path)
        slides = presentation.Slides
        
        for i, slide in enumerate(tqdm(slides, desc="å¯¼å‡ºå¹»ç¯ç‰‡")):
            slide_img_path = os.path.join(image_dir, f"slide_{i:03d}.png")
            slide.Export(slide_img_path, 'PNG')
        
        presentation.Close()
        powerpoint.Quit()
    except Exception as e:
        print(f"æ‰“å¼€PPTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        shutil.rmtree(temp_dir, ignore_errors=True)
        return
    
    print("æ­£åœ¨ç”Ÿæˆè§†é¢‘ç‰‡æ®µ...")
    clips = []
    image_files = sorted(os.listdir(image_dir))
    num_slides = len(image_files)
    audio_dir = "voice_audio"  # è·¯å¾„éœ€ä¸è¯­éŸ³ç”Ÿæˆå¤„ä¿æŒä¸€è‡´

    for i in range(num_slides):
        current_img_path = os.path.join(image_dir, image_files[i])
        slide_duration = durations[i] if durations and i < len(durations) else 5
        current_clip = ImageClip(current_img_path).with_duration(slide_duration)
        clips.append(current_clip)
        
        if i < num_slides - 1:
            next_img_path = os.path.join(image_dir, image_files[i+1])
            transition_clip = create_transition_clip(
                current_img_path, next_img_path,
                duration=transition_duration, fps=fps
            )
        current_clip = ImageClip(current_img_path).with_duration(slide_duration)

        audio_path = os.path.join(audio_dir, f"slide_{i:03d}.mp3")
        if os.path.exists(audio_path):
            audio_clip = AudioFileClip(audio_path)
            slide_duration = audio_clip.duration  # ä½¿ç”¨éŸ³é¢‘å®é™…é•¿åº¦
            current_clip = current_clip.with_duration(slide_duration).with_audio(audio_clip)
        clips.append(current_clip)
    
    
    print("æ­£åœ¨åˆå¹¶è§†é¢‘ç‰‡æ®µ...")
    final_clip = concatenate_videoclips(clips, method="compose")
    
    print("æ­£åœ¨ä¿å­˜è§†é¢‘...")
    final_clip.write_videofile(output_path, fps=fps, codec="libx264")
    
    time.sleep(1)
    shutil.rmtree(temp_dir, ignore_errors=True)
    
    print(f"ğŸ‰ è§†é¢‘å·²æˆåŠŸä¿å­˜è‡³: {output_path}")

def create_transition_clip(img_path1, img_path2, duration, fps):
    img1 = Image.open(img_path1).convert('RGB')
    img2 = Image.open(img_path2).convert('RGB')
    
    width, height = max(img1.size, img2.size)
    img1 = img1.resize((width, height), Image.LANCZOS)
    img2 = img2.resize((width, height), Image.LANCZOS)
    
    frames = []
    num_frames = int(duration * fps)
    
    for i in range(num_frames):
        alpha = i / (num_frames - 1)
        blended = Image.blend(img1, img2, alpha)
        frame_array = np.array(blended)
        frames.append(frame_array)
    
    return ImageSequenceClip(frames, fps=fps)

if __name__ == '__main__':
    topic = input('è¾“å…¥ä¸»é¢˜:')
    initial_pages = 11
    
    ppt_content, refined_topic = generate_ppt_content(topic, initial_pages)

# ç»Ÿè®¡æ–‡å­—æ€»æ•°
    all_text = ppt_content['title'] + ''.join(
        page['title'] + ''.join(block['title'] + block['description'] for block in page['content'])
        for page in ppt_content['pages']
    )

# æ ¹æ®å†…å®¹é‡æ–°ä¼°ç®—é¡µæ•°
    estimated_pages = estimate_ppt_pages_from_content(all_text)

    # è‹¥å®é™…ç”Ÿæˆé¡µæ•°å’Œé¢„æœŸä¸ä¸€è‡´ï¼Œé‡æ–°ç”Ÿæˆ
    if len(ppt_content['pages']) != estimated_pages:
        print(f"ğŸ” å†…å®¹åå°‘æˆ–åå¤šï¼Œé‡æ–°ç”Ÿæˆ {estimated_pages} é¡µå†…å®¹...")
        ppt_content, refined_topic = generate_ppt_content(topic, estimated_pages)

        ppt_path = generate_ppt_file(refined_topic, ppt_content)
    
        ppt_path_background = add_background_to_ppt(
            ppt_path_background=ppt_path,
            bg_image_path="R-C.jpg",
        )

    durations = get_slide_durations_from_content(ppt_content, seconds_per_char=0.15, min_duration=1)
    durations[0] = 5
    generate_voice_for_slides(ppt_content)
    output_path = os.path.splitext(ppt_path)[0] + ".mp4"
    ppt_to_video(
        ppt_path_background,
        output_path,
        durations=durations,
        fps=30,
        transition_duration=1
    )

    os.remove(ppt_path)
    os.remove(ppt_path_background)
    print(f"ä¸´æ—¶ç”Ÿæˆçš„PPTæ–‡ä»¶ {ppt_path} å·²åˆ é™¤ã€‚")
